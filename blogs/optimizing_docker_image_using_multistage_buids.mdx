---
title: Optimizing Docker Images Using Multistage Builds
date: '23/10/2024'
description: In this I will take you through deploying a docker container on a GCP compute engine 
---

I wanted to deploy an application on docker because it is bugging me why I am not using docker as I have heard a lot about how it eases the deployment process of modern software, so I decided to do the labour work and tried to figure out how to do it (The docker community on dicord is amazing). I am fairly new to the container world and I just wanted to put this blog up on my personal portfolio so that i can look cool and have all the SEO in the Google Search Engine....
<br/>
Oh sorry, we are here to deploy the application more specifically an application that is running inside a container.
<br/>
Step 1: Write a Dockerfile in the root of your project, I am using a simple vite-react application 
for deployment because I am a simple person. You can clone the <a href={"https://github.com/gaurav-2-0-0-2/vite-docker-gcp"}>project</a> if you love your time.
<br/>
Now run these:
<br/>
```CMD

cd vite-docker-gcp
npm install
npm run dev

```
<br/>
Your application is running on http://localhost:5173, go check in your browser. In the root of your project create a Dockerfile. A dockerfile is necessary to build an image of the application. An image is like a blueprint for the container. We are going to use this image to run our container and the amazing thing is you can run multiple containers with the same image, awesome. 
<br/>
```Dockerfile

FROM node:20-alpine as base

WORKDIR ./src 

COPY package*.json .

RUN npm install

COPY . .

RUN npm run build

npm i -g serve

EXPOSE 3000

CMD ["serve", "-s", "dist"]

```
<br/>
What is happening ?
<ul style={{ paddingLeft:'40px', listStyleType: 'dot' }}>
    <li>We are pulling a node:20-alpine image from docker hub</li>
    <li>Telling docker, set working directory inside the container to src/</li>
    <li>Copying package.json and package-lock.json in docker image's filesystem</li>
    <li>Running npm install to install dependecies at build time</li>
    <li>Copying the files in docker image's filesystem</li>
    <li>Building our application (this will give us a dist folder)</li>
    <li>Installing serve package to serve dist's content on the port 3000</li>
    <li>Exposing the port 3000 </li>
    <li>CMD command always run inside a container, so we are going to serve our dist using this command</li>
</ul> 
<br/>
This is enough to build the image, now if we run:
<br/>
```CMD docker build . -t vite-docker:latest```
<br/>
It will build an image and you can run containers
<br/>
But it is not a good approach to run a container with the whole code since the only thing we need is the build directory after `npm run build` command. So to optimize we are going to use multistage Dockerfile. In a multistage Dockerfile, different stages are created to serve different purposes, for example to separate development and production environment.
<br/>
```Dockerfile

FROM node:20-alpine as base
WORKDIR ./src 
COPY package*.json .
RUN npm install
COPY . .

FROM base as build
RUN npm run build

FROM node:20-alpine as main
WORKDIR ./app
COPY --from=build ./src/dist ./dist
RUN npm i -g serve
EXPOSE 3000
CMD ["serve", "-s", "dist"]

```
<br/>
In this file we have three stages:
base - this stage will setup the whole thing that we did in above Dockerfile upto step 5
build - this stage will build the whole code
main - this stage will serve the dist (which has post-build code)
<br/>
Now when we run the image build process we specify a target like this:
<br/>
```CMD 
docker build . -t vite-docker:latest --target=main
```
<br/>
What this command will do is, it will start building the image from main stage and as it will reach the COPY command, it goes to build stage and since the build stage is itself running from base stage so it will run the base stage first. After getting the dist folder from build, it comes back to the COPY command and will just copy the content of dist folder which is present in src directory at build stage to the app/dist in main stage. The next steps are same as steps 7, 8, 9 from the first Dockerfile that we created.


